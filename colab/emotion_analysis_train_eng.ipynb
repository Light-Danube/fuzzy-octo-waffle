{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["В даному ноутбуку вказано учбову реалізацію запропонованої в випускній-кваліфікаційній роботі\n","системи аналізу настроїв у текстових повідомленнях\n","з використанням 2 напрямків: загальної класифікації типу\n","\"позитивне\"/\"негативне\" чи спеціалізованої емоції типу\n","\"злість\", \"сум\".\n","\n","Система підтримує моделі для аналізу настроїв у текстових повідомленнях, тренованих на українських чи англомовних наборах даних, які були відповідно розмічені перед тренуванням моделей.\n","\n","Для правильного функціонування рекомендується читати підказки в текстових клітинках та виконувати дії послідовно.\n","Тренування власних моделей для аналізу настроїв у текстових повідомленнях винесено в окремі ноутбуки:\n","- english training: https://colab.research.google.com/drive/1xLJEz-VzsutVU9KdHLAOIsrQ7WBISftw?usp=sharing\n","- ukranian training: https://colab.research.google.com/drive/1aw7bWfR4n12vzYl2z1_VGZKJIFhECvZK?usp=sharing"],"metadata":{"id":"bOhtVA_LidDv"}},{"cell_type":"markdown","source":["# Train your english emotion analysis model here."],"metadata":{"id":"AjHjtsNUWkY9"}},{"cell_type":"markdown","source":["STEP #1: Run next cell to setup needed libraries for work."],"metadata":{"id":"InRXWCD_AGhq"}},{"cell_type":"code","source":["# Cell 1: Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow as tf\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, LSTM\n","from tensorflow.keras.models import Sequential\n"],"metadata":{"id":"NUAf0hDpWeUc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #2: Load your data: train, validate, test files."],"metadata":{"id":"sKbL-c5qAIMV"}},{"cell_type":"code","source":["#train_texts, train_labels = load_file('train.txt')\n","#val_texts, val_labels = load_file('val.txt')\n","#test_texts, test_labels = load_file('test.txt')"],"metadata":{"id":"7jKUov_NWevx","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1713972182947,"user_tz":-180,"elapsed":12,"user":{"displayName":"Dan SokFIT","userId":"07805205791165333924"}},"outputId":"749bf139-cce3-4642-e0bd-4abce72f0d10"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'load_file' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-21fc2a8f4060>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_file' is not defined"]}]},{"cell_type":"markdown","source":["STEP #3: Use next cell to prepare data for proper usage for build-up model"],"metadata":{"id":"2MmlnrvXAIzu"}},{"cell_type":"code","source":["train_texts, train_labels = load_file('train.txt')\n","val_texts, val_labels = load_file('val.txt')\n","test_texts, test_labels = load_file('test.txt')"],"metadata":{"id":"Ec2SEj-4WfH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert labels to numerical values\n","label_to_index = {'sadness': 0, 'joy': 1, 'anger': 2, 'fear': 3}\n","train_labels = [label_to_index[label] for label in train_labels]\n","val_labels = [label_to_index[label] for label in val_labels]\n","test_labels = [label_to_index[label] for label in test_labels]\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(train_texts)\n","train_sequences = tokenizer.texts_to_sequences(train_texts)\n","val_sequences = tokenizer.texts_to_sequences(val_texts)\n","test_sequences = tokenizer.texts_to_sequences(test_texts)\n","\n","# Pad the sequences\n","max_length = max([len(seq) for seq in train_sequences + val_sequences + test_sequences])\n","train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n","val_padded = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n","test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')"],"metadata":{"id":"5wtGw-UKraVe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #4: Training your model: may take some time"],"metadata":{"id":"-kaa3z_yV82Z"}},{"cell_type":"code","source":["# Cell 4: Build and train the RNN (LSTM) model\n","model = Sequential()\n","model.add(Embedding(len(tokenizer.word_index) + 1, 128, input_length=max_length))\n","model.add(LSTM(64))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(4, activation='softmax'))  # 4 classes: sadness, joy, anger, fear\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(train_padded, np.array(train_labels), epochs=10, batch_size=32, validation_data=(val_padded, np.array(val_labels)))"],"metadata":{"id":"773kVbIEWfcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_padded, np.array(test_labels))\n","print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')"],"metadata":{"id":"39aHwAqdrlK_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #5: Test your model on real examples:"],"metadata":{"id":"TTjHjqT0WC-g"}},{"cell_type":"code","source":["# Cell 5: Test the model with user input\n","user_input = input(\"Enter a text to test the model: \")\n","user_sequence = tokenizer.texts_to_sequences([user_input])\n","user_padded = pad_sequences(user_sequence, maxlen=max_length, padding='post')\n","prediction = model.predict(user_padded)\n","predicted_label = np.argmax(prediction)\n","label_index = {0: 'sadness', 1: 'joy', 2: 'anger', 3: 'fear'}\n","print(f\"Predicted emotion: {label_index[predicted_label]}\")"],"metadata":{"id":"cnI9hsZ9tHYk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #6 (opt) Save your model and download it to use on colab/local system in .h5 format."],"metadata":{"id":"iNbECa4DWIFW"}},{"cell_type":"code","source":["import pickle\n","with open('tokenizer.pkl', 'wb') as tokenizer_file:\n","    pickle.dump(tokenizer, tokenizer_file)\n","\n","model.save('nlp.h5')"],"metadata":{"id":"Y74OS-sCWgF2"},"execution_count":null,"outputs":[]}]}