{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP66GDUwbc1Ziw9BPnYscUw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["В даному ноутбуку вказано учбову реалізацію запропонованої в випускній-кваліфікаційній роботі\n","україномовної моделі для запрононованої та реалізованої в випускній-кваліфікаційній роботі системи аналізу настроїв у текстових повідомленнях.\n","\n","Був використаний датасет з нечіткою класифікацією типу позитивний/негативний.\n","\n","Сама система знаходиться в окремому ноутбуці за наступним посиланням\n","https://colab.research.google.com/drive/1ZmlgVkDFcaf7xYx6UNqIIsH7YCz0MVJs?usp=sharing"],"metadata":{"id":"bOhtVA_LidDv"}},{"cell_type":"markdown","source":["# Train your ukranian emotion analysis model here."],"metadata":{"id":"AjHjtsNUWkY9"}},{"cell_type":"markdown","source":["STEP #1: Run next cell to setup needed libraries for work."],"metadata":{"id":"InRXWCD_AGhq"}},{"cell_type":"code","source":["# Cell 1: Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import tensorflow as tf\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, LSTM\n","from tensorflow.keras.models import Sequential\n","from google.colab import drive"],"metadata":{"id":"sMeF1l429DFv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cell 2: Mount Google Drive to access files\n","drive.mount('/content/drive')"],"metadata":{"id":"LL0EXE7S3aYm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #2: Load your data: train, validate, test files."],"metadata":{"id":"sKbL-c5qAIMV"}},{"cell_type":"code","source":["# Cell 3: Load your data\n","def load_file(file_path):\n","    \"\"\"\n","    Function to load sentiment data from a CSV file.\n","\n","    Args:\n","    file_path (str): Path to the CSV file.\n","\n","    Returns:\n","    list, list: List of texts and corresponding labels.\n","    \"\"\"\n","    df = pd.read_csv(file_path)\n","    texts = df['word'].tolist()\n","    labels = df['pos_neg'].tolist()\n","    return texts, labels\n","\n","train_texts, train_labels = load_file('/content/drive/MyDrive/sentiment_ukr.csv')\n"],"metadata":{"id":"7jKUov_NWevx","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1713972182947,"user_tz":-180,"elapsed":12,"user":{"displayName":"Dan SokFIT","userId":"07805205791165333924"}},"outputId":"749bf139-cce3-4642-e0bd-4abce72f0d10"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'load_file' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-21fc2a8f4060>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_file' is not defined"]}]},{"cell_type":"code","source":["#(Op) Uncomment & load your file manually:\n","#from google.colab import files\n","#uploaded = files.upload()"],"metadata":{"id":"EHPmp5_n3lfs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #3: Use next cell to prepare data for proper usage for build-up model"],"metadata":{"id":"2MmlnrvXAIzu"}},{"cell_type":"code","source":["# Cell 4: Split data into train, validation, and test sets\n","train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)\n","train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)"],"metadata":{"id":"22vQPt-m3kOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert labels to numerical values\n","label_to_index = {'sadness': 0, 'joy': 1, 'anger': 2, 'fear': 3}\n","train_labels = [label_to_index[label] for label in train_labels]\n","val_labels = [label_to_index[label] for label in val_labels]\n","test_labels = [label_to_index[label] for label in test_labels]\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(train_texts)\n","train_sequences = tokenizer.texts_to_sequences(train_texts)\n","val_sequences = tokenizer.texts_to_sequences(val_texts)\n","test_sequences = tokenizer.texts_to_sequences(test_texts)\n","\n","# Pad the sequences\n","max_length = max([len(seq) for seq in train_sequences + val_sequences + test_sequences])\n","train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n","val_padded = pad_sequences(val_sequences, maxlen=max_length, padding='post')\n","test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')"],"metadata":{"id":"5wtGw-UKraVe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #4: Training your model: may take some time"],"metadata":{"id":"-kaa3z_yV82Z"}},{"cell_type":"code","source":["# Cell 4: Build and train the RNN (LSTM) model\n","model = Sequential()\n","model.add(Embedding(len(tokenizer.word_index) + 1, 128, input_length=max_length))\n","model.add(LSTM(64))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(4, activation='softmax'))  # 4 classes: sadness, joy, anger, fear\n","\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","model.fit(train_padded, np.array(train_labels), epochs=10, batch_size=32, validation_data=(val_padded, np.array(val_labels)))"],"metadata":{"id":"773kVbIEWfcs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_padded, np.array(test_labels))\n","print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')"],"metadata":{"id":"39aHwAqdrlK_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #5: Test your model on real examples:"],"metadata":{"id":"TTjHjqT0WC-g"}},{"cell_type":"code","source":["# Cell 5: Test the model with user input\n","user_input = input(\"Enter a text to test the model: \")\n","user_sequence = tokenizer.texts_to_sequences([user_input])\n","user_padded = pad_sequences(user_sequence, maxlen=max_length, padding='post')\n","prediction = model.predict(user_padded)\n","predicted_label = np.argmax(prediction)\n","label_index = {0: 'sadness', 1: 'joy', 2: 'anger', 3: 'fear'}\n","print(f\"Predicted emotion: {label_index[predicted_label]}\")"],"metadata":{"id":"cnI9hsZ9tHYk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["STEP #6: Save your model and download it to use on colab/local system in .pb format."],"metadata":{"id":"iNbECa4DWIFW"}},{"cell_type":"code","source":["import pickle\n","with open('tokenizer.pkl', 'wb') as tokenizer_file:\n","    pickle.dump(tokenizer, tokenizer_file)\n","\n","model.save('nlp.h5')"],"metadata":{"id":"JmitUZjx9FCk"},"execution_count":null,"outputs":[]}]}